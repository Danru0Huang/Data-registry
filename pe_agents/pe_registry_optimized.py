# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„MDRæ³¨å†Œç³»ç»Ÿ - è§£å†³è¶…tokené—®é¢˜
"""

from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
import os
import sys
import pandas as pd
import numpy as np
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from Metadata_Regirstry.tools import tools
from config import Config

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®DeepSeek APIé…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_BASE_URL"] = os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1")  

llm = ChatOpenAI(
    model="deepseek-chat",  
    temperature=0,
    max_retries=3  
)

# ç²¾ç®€çš„æç¤ºè¯ - å‡å°‘tokenä½¿ç”¨
planner_prompt = """
ä½ æ˜¯ä¸€ä¸ªMDRæ³¨å†Œè®¡åˆ’æ™ºèƒ½ä½“ï¼Œæ ¹æ®è¾“å…¥ç”Ÿæˆæ³¨å†Œè®¡åˆ’ã€‚

**æ ¸å¿ƒè§„åˆ™ï¼š**
- å€¼ä¸ºç©ºåˆ™è·³è¿‡å€¼åŸŸå’Œå€¼å«ä¹‰æ³¨å†Œ
- ä¸¥æ ¼æŒ‰ç…§è¾“å…¥å€¼æ³¨å†Œï¼Œä¸ç¿»è¯‘ï¼Œä¿æŒåŸå§‹è¯­è¨€
- å€¼ä¸ºç©ºç”¨register_value_domain_with_relationshipï¼Œæœ‰å€¼ç”¨register_value_domain_with_values

**7æ­¥æ³¨å†Œæµç¨‹ï¼š**
1. object_class: register_object_class(object_class="{object_class}")
2. property: register_property(property_name="{property}")
3. concept_domain: register_concept_domain(concept_domain="{concept_domain}")  
4. data_element_concept: register_data_element_concept_with_relationships(...)
5. value_domain: æ ¹æ®æ˜¯å¦æœ‰å€¼é€‰æ‹©æ³¨å†Œæ–¹å¼
6. value_meanings: å€¼å’Œå€¼å«ä¹‰éƒ½éç©ºæ—¶æ³¨å†Œ
7. data_element: register_data_element_with_relationships(...)

è¾“å…¥ï¼šæœ¬ä½“ç±»='{ontology_class}', å±æ€§='{attribute}', å€¼='{values}', å€¼å«ä¹‰='{value_meanings}'
ç”Ÿæˆç®€æ´çš„æ³¨å†Œè®¡åˆ’ã€‚
"""

# ç®€åŒ–çš„æ‰§è¡Œå™¨æç¤ºè¯
executor_prompt = """
æ‰§è¡ŒMDRæ³¨å†Œè®¡åˆ’ï¼Œä¸¥æ ¼æŒ‰ç…§æ­¥éª¤æ‰§è¡Œã€‚

**æ‰§è¡Œè§„åˆ™ï¼š**
- è·³è¿‡è®¡åˆ’ä¸­æ ‡è®°ä¸ºè·³è¿‡çš„æ­¥éª¤
- ä¿æŒåŸå§‹è¯­è¨€ï¼Œä¸ç¿»è¯‘
- ç©ºå€¼å¤„ç†ï¼šç”¨register_value_domain_with_relationship
- æœ‰å€¼å¤„ç†ï¼šç”¨register_value_domain_with_values + register_value_meanings_with_relationship

å½“å‰ä»»åŠ¡ï¼š{step_description}

å·¥å…·è°ƒç”¨æ ¼å¼ï¼š
1. register_object_class(object_class="...")
2. register_property(property_name="...")
3. register_concept_domain(concept_domain="...")
4. register_data_element_concept_with_relationships(...)
5. register_value_domain_with_values(...) æˆ– register_value_domain_with_relationship(...)
6. register_value_meanings_with_relationship(...)
7. register_data_element_with_relationships(...)

è¿”å›æ‰§è¡Œç»“æœæˆ–é”™è¯¯ä¿¡æ¯ã€‚
"""

# åˆå§‹åŒ–
planner = load_chat_planner(llm, planner_prompt)
executor = load_agent_executor(llm, tools, verbose=False)  # å‡å°‘verboseè¾“å‡º
agent = PlanAndExecute(planner=planner, executor=executor, verbose=False)

# è¯»å–MDM-01å…±äº«åŸŸæ•°æ®
df = pd.read_excel(Config.SHARED_DOMAIN_FILE)

# ä¿®å¤åˆ—åç¼–ç é—®é¢˜
expected_columns = ['æœ¬ä½“ç±»', 'å±æ€§', 'å€¼', 'å€¼å«ä¹‰', 'ä»£ç ', 'æ•°æ®ç±»å‹', 'å±æ€§æè¿°', 'æ¥æºæ–‡ä»¶']
if len(df.columns) == len(expected_columns):
    df.columns = expected_columns
    print("å·²ä¿®å¤shared_domain.xlsxçš„åˆ—åç¼–ç é—®é¢˜")

def process_data(df):
    """å¤„ç†æ•°æ®æ ¼å¼"""
    grouped_data = {}
    for _, row in df.iterrows():
        ontology_class = row["æœ¬ä½“ç±»"]
        attribute = row["å±æ€§"]
        value_str = row.get("å€¼", "")
        meaning_str = row.get("å€¼å«ä¹‰", "")

        # å¤„ç†ç©ºå€¼
        if pd.isna(value_str) or value_str == "nan" or value_str == "null":
            value_str = ""
        if pd.isna(meaning_str) or meaning_str == "nan" or meaning_str == "null":
            meaning_str = ""

        if ontology_class not in grouped_data:
            grouped_data[ontology_class] = {}
        
        grouped_data[ontology_class][attribute] = {
            "value_str": value_str,
            "meaning_str": meaning_str
        }
    return grouped_data

def process_single_attribute(ontology_class, attribute, details):
    """å¤„ç†å•ä¸ªå±æ€§ï¼Œå‡å°‘tokenä½¿ç”¨"""
    try:
        # ç®€åŒ–çš„è¾“å…¥æè¿°
        has_values = "æœ‰" if details['value_str'] else "æ— "
        has_meanings = "æœ‰" if details['meaning_str'] else "æ— "
        
        input_description = (
            f"æœ¬ä½“ç±»='{ontology_class}', å±æ€§='{attribute}', "
            f"å€¼{has_values}, å€¼å«ä¹‰{has_meanings}"
        )
        
        result = agent.invoke({"input": input_description})
        print(f"âœ“ {ontology_class}.{attribute}")
        return True
        
    except Exception as e:
        print(f"âœ— {ontology_class}.{attribute}: {str(e)[:100]}")
        return False

def process_in_small_batches(data, batch_size=1):
    """æ›´å°çš„æ‰¹æ¬¡å¤„ç†ï¼Œé¿å…è¶…token"""
    total_success = 0
    total_error = 0
    
    ontology_classes = list(data.keys())
    
    for i in range(0, len(ontology_classes), batch_size):
        batch_classes = ontology_classes[i:i + batch_size]
        
        print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{len(ontology_classes)//batch_size + 1}")
        
        for ontology_class in batch_classes:
            print(f"\nğŸ¥ å¤„ç†æœ¬ä½“ç±»: {ontology_class}")
            attributes = data[ontology_class]
            
            for attribute, details in attributes.items():
                success = process_single_attribute(ontology_class, attribute, details)
                if success:
                    total_success += 1
                else:
                    total_error += 1
                
                # æ¯ä¸ªå±æ€§å¤„ç†åçŸ­æš‚æš‚åœï¼Œé¿å…APIé™åˆ¶
                import time
                time.sleep(0.5)
    
    print(f"\nğŸ“Š æ³¨å†Œå®Œæˆç»Ÿè®¡:")
    print(f"âœ… æˆåŠŸ: {total_success}")
    print(f"âŒ å¤±è´¥: {total_error}")
    print(f"ğŸ“ˆ æ€»è®¡: {total_success + total_error}")

# ä¸»æµç¨‹
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹MDM-01å…±äº«åŸŸæ•°æ®æ³¨å†Œ (ä¼˜åŒ–ç‰ˆ)")
    
    data = process_data(df)
    print(f"ğŸ“‹ å…±å¤„ç† {len(data)} ä¸ªæœ¬ä½“ç±»")
    
    # ä½¿ç”¨æ›´å°çš„æ‰¹æ¬¡å’Œç®€åŒ–çš„å¤„ç†
    process_in_small_batches(data, batch_size=1)
    
    print("\nâœ¨ å…¨éƒ¨å®Œæˆ!")